{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdRzS4vaxO6S"
   },
   "source": [
    "# **Case Study: Condition Monitoring of a Complex Hydraulic System**\n",
    "The system under study consist of a primary working circuit (**a** in figure below) and a secundary circuit for cooling and filtration (**b** in figure below). This system was developed as a test rig allowing to change the state or condition of various components. [Paper available here](https://ieeexplore.ieee.org/document/7151267)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0v_05F-NbaT"
   },
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=1Phrt8RMtkQ513iRafEY9rcsKvmszN9wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given test system is equipped with **several sensors measuring process values** such as pressure (PS1-PS6), flow (FS1, FS2), temperature (TS1-TS5), electrical power (EPS1) and vibration (VS1). In addition, sensors for particle contamination (CS and MCS, COPS) and oil parameter monitoring (COPS) are integrated. \n",
    "\n",
    "\n",
    "The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values **while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied**. The dataset is available in the following [link](https://archive-beta.ics.uci.edu/dataset/447/condition+monitoring+of+hydraulic+systems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUPUIcnc0Ylu"
   },
   "source": [
    "# **Data Inspection**\n",
    "\n",
    "The data has been collected from **17 sensors** (6 of pressure, 1 motor power, 2 volume flow, 4 temperature, 1 vibration, 1 cooling efficiency, 1 cooling power and 1 efficiency factor) over **2205 cycles** of 60 sec each (1.5 days). The sensors' sampling rate in different depending on the dynamics of the underlying physical values. The sensors involved with their respective unit of measure and samplig rate are reported in the Table below.\n",
    "\n",
    "\n",
    "| Sensor | Physical quantity          | Unit  | Sampling rate |\n",
    "|:--------|:---------------------------|:-------|:---------------|\n",
    "| PS1    | Pressure                  | bar   | 100 Hz        |\n",
    "| PS2    | Pressure                  | bar   | 100 Hz        |\n",
    "| PS3    | Pressure                  | bar   | 100 Hz        |\n",
    "| PS4    | Pressure                  | bar   | 100 Hz        |\n",
    "| PS5    | Pressure                  | bar   | 100 Hz        |\n",
    "| PS6    | Pressure                  | bar   | 100 Hz        |\n",
    "| EPS1   | Motor power               | W     | 100 Hz        |\n",
    "| FS1    | Volume flow               | l/min | 10 Hz         |\n",
    "| FS2    | Volume flow               | l/min | 10 Hz         |\n",
    "| TS1    | Temperature               | 째C    | 1 Hz          |\n",
    "| TS2    | Temperature               | 째C    | 1 Hz          |\n",
    "| TS3    | Temperature               | 째C    | 1 Hz          |\n",
    "| TS4    | Temperature               | 째C    | 1 Hz          |\n",
    "| VS1    | Vibration                 | mm/s  | 1 Hz          |\n",
    "| CE     | Cooling efficiency (virtual) | %    | 1 Hz          |\n",
    "| CP     | Cooling power (virtual)   | kW    | 1 Hz          |\n",
    "| SE     | Efficiency factor         | %     | 1 Hz          |\n",
    "\n",
    "The raw process sensors output is provided in separate dedicated files (one file per sensor). Each file is structured as a matrix (tab-delimited) with the rows representing the cycles and the columns the data samples within a cycle.\n",
    "\n",
    "In order to simulate different scenarios, from normal functioning to faults of different severities, especific parameters of some components are configurable. In the following table are listed the configurable components and the respective controllable parameter.\n",
    "\n",
    "| |Component  |Condition              |Control Parameter    |\n",
    "|:-:|:-----------|:-----------------------|:---------------------|\n",
    "|1|Cooler (C1)| Cooling power decrease| Fan duty cycle of C1|\n",
    "|2|Valve (V10)| Switching characteristic degradation| Control current of V10|\n",
    "|3|Pump (MP1)| Internal leakage|Switchable bypass orifices (V9)|\n",
    "|4|Accumulators (A1-A4)| Gas leakage| Accumulators A1-A4 with different precharge pressure|\n",
    "\n",
    "The condition of each component cycle-wise is provided in the file ```profile.txt```. ```profile.txt``` contains a matrix whose rows represent the cycles (2205), all columns but number 5 are the condition of each component and the last column is a flag indicating if stady state is reached or not. The columns order and entries are read in the following way:\n",
    "\n",
    "1. **Cooler condition** (%):\n",
    "\t* 3: close to total failure\n",
    "\t* 20: reduced effifiency\n",
    "\t* 100: full efficiency\n",
    "\n",
    "2. **Valve condition** (%):\n",
    "\t* 100: optimal switching behavior\n",
    "\t* 90: small lag\n",
    "\t* 80: severe lag\n",
    "\t* 73: close to total failure\n",
    "\n",
    "3. **Internal pump leakage**:\n",
    "\t* 0: no leakage\n",
    "\t* 1: weak leakage\n",
    "\t* 2: severe leakage\n",
    "\n",
    "4. **Hydraulic accumulator** (bar):\n",
    "\t* 130: optimal pressure\n",
    "\t* 115: slightly reduced pressure\n",
    "\t* 100: severely reduced pressure\n",
    "\t* 90: close to total failure\n",
    "\n",
    "5. **Stable flag**:\n",
    "\t* 0: conditions were stable\n",
    "\t* 1: static conditions might not have been reached yet\n",
    "\n",
    "\n",
    "\n",
    "<!--- \n",
    "\n",
    "The number of instances is 2205, while the number of attrbiutes is 3680 (8x60 (1 Hz) + 2x600 (10 Hz) + 7x6000 (100 Hz)). The attributes are the sensor data(all numeric and continuous) from measurements taken at the same point in time, respectively, of a hydraulic test rig's working cycle.) \n",
    "\n",
    "The sensors were read with different sampling rates, leading to different numbers of attributes per sensor despite they were all exposed to the same working cycle.\n",
    "   \n",
    "   1. Pressure sensors (PS1-6): 100 Hz, 6000 attributes per sensor (6 sensors)\n",
    "   2. Motor power sensor (EPS1): 100 Hz, 6000 attributes per sensor (1 sensor)\n",
    "   3. Volume flow sensors (FS1/2): 10 Hz, 600 attributes per sensor (2 sensors)\n",
    "   4. Temperature sensors (TS1-4): 1 Hz, 60 attributes per sensor (4 sensors)\n",
    "   5. Vibration sensor (VS1): 1 Hz, 60 attributes per sensor (1 sensor)\n",
    "   6. Efficiency factor (SE): 1 Hz, 60 attributes per sensor (1 sensor)\n",
    "   7. Virtual cooling efficiency sensor (CE): 1 Hz, 60 attributes per sensor (1 sensor)\n",
    "   8. Virtual cooling power sensor (CP): 1 Hz, 60 attributes per sensor (1 sensor)\n",
    "\n",
    "Note that if an attribute value is missing it has None value.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Due to the different sampling rates, the data is stored in groups by sampling period\n",
    "\n",
    "EXPLAIN DATA SUBSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import graphviz as gr\n",
    "import ges\n",
    "def load_data(dir_array, dir_add, idx_arr=[]):\n",
    "    i = 0\n",
    "    for file in dir_array:\n",
    "        temp = np.loadtxt(dir_add+file, delimiter='\\t', skiprows=0, dtype=float)\n",
    "        temp = temp[idx_arr,:]\n",
    "        temp = temp.flatten()\n",
    "        if i ==0:\n",
    "            X = np.array([], dtype=np.int64).reshape(len(temp),0)\n",
    "        X = np.hstack([X, temp.reshape(-1,1)])\n",
    "        i=i+1\n",
    "    return X\n",
    "\n",
    "def save_adjMat_score(file_name, estimate, score):\n",
    "    # open the file in the write mode\n",
    "    f = open('Results/adjMat_' + file_name, 'w')\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    for i in range(estimate.shape[0]):\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(estimate[i,:])\n",
    "    # close the file\n",
    "    f.close()\n",
    "    print('File saved: ', 'adjMat_' + file_name)\n",
    "    \n",
    "    f = open('Results/score_'+file_name+'.txt', 'w')\n",
    "    # create the csv writer\n",
    "    f.write(str(score))\n",
    "    # close the file\n",
    "    f.close()\n",
    "    print('File saved: ', 'score_' + file_name)\n",
    "    \n",
    "# def create_graph(adjMat):\n",
    "#     f = gr.Digraph(filename = 'graph1.gv')\n",
    "#     for name in nodes:\n",
    "#         f.node(name, name)\n",
    "\n",
    "#     # Specify edges\n",
    "#     for row in range(17):\n",
    "#         for col in range(17):\n",
    "#             if adjMat[row,col] == 1:\n",
    "#                 f.edge(nodes[row],nodes[col])\n",
    "#     return f\n",
    "def create_graph(adjMat, nodes, labels):\n",
    "    f = gr.Digraph(filename = 'graph1.gv')\n",
    "    for name,label in zip(nodes,labels):\n",
    "        f.node(name, label)\n",
    "\n",
    "    # Specify edges\n",
    "    for row in range(adjMat.shape[0]):\n",
    "        for col in range(adjMat.shape[1]):\n",
    "            if adjMat[row,col] == 1:\n",
    "                f.edge(nodes[row],nodes[col])\n",
    "    return f\n",
    "\n",
    "nodes_full = [\"CE\",\"CP\",\"SE\",\"TS1\",\"TS2\",\"TS3\",\"TS4\",\"VS1\",\"FS1\",\"FS2\",\"EPS1\",\"PS1\",\"PS2\",\"PS3\",\"PS4\",\"PS5\",\"PS6\"]\n",
    "# label =[\"CE\",\"CP\",\"SE\",\"TS1\",\"TS2\",\"TS3\",\"TS4\",\"VS1\",\"FS1\",\"FS2\",\"EPS1\",\"PS1\",\"PS2\",\"PS3\",\"PS4\",\"PS5\",\"PS6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1Hz files\n",
      "----------------------------------------\n",
      "['CE.txt', 'CP.txt', 'SE.txt', 'TS1.txt', 'TS2.txt', 'TS3.txt', 'TS4.txt', 'VS1.txt']\n",
      "Data loaded. Matrix shape: (86940, 8)\n",
      "----------------------------------------\n",
      "10Hz files\n",
      "----------------------------------------\n",
      "['FS1.txt', 'FS2.txt']\n",
      "Data loaded. Matrix shape: (869400, 2)\n",
      "Data sub sampled. Matrix shape: (86940, 2)\n",
      "----------------------------------------\n",
      "100Hz files\n",
      "----------------------------------------\n",
      "['EPS1.txt', 'PS1.txt', 'PS2.txt', 'PS3.txt', 'PS4.txt', 'PS5.txt', 'PS6.txt']\n",
      "Data loaded. Matrix shape: (8694000, 7)\n",
      "Data sub sampled. Matrix shape: (86940, 7)\n",
      "----------------------------------------\n",
      "Whole data matrix created!!\n",
      "----------------------------------------\n",
      "(86940, 17)\n"
     ]
    }
   ],
   "source": [
    "# Removing non stable cycles\n",
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_stable = np.where(profile[:,4] == 0)\n",
    "idx_stable = np.asarray(idx_stable)[0]\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "X_1Hz = load_data(arr,'data/1Hz/', idx_arr=idx_stable) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', X_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "X_10Hz = load_data(arr,'data/10Hz/', idx_arr=idx_stable)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', X_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "X_10Hz_sub=X_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', X_10Hz_sub.shape)\n",
    "\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "X_100Hz = load_data(arr,'data/100Hz/', idx_arr=idx_stable)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', X_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "X_100Hz_sub=X_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', X_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "data = np.concatenate((X_1Hz,X_10Hz_sub,X_100Hz_sub),1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure below shows the measured values of three different sensors of the system during the whole measuring period (all 2205 cycles) \n",
    "\n",
    "SUBPLOT WITH ALL SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_1Hz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(t, \u001b[43mX_1Hz\u001b[49m[:\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# plt.plot(t1, X_1Hz[0:-1:100,3])\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime [s]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_1Hz' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temperature (1 Hz)\n",
    "t = np.linspace(0, 60*5, num=60*5)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t, X_1Hz[:60*5,3])\n",
    "# plt.plot(t1, X_1Hz[0:-1:100,3])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Temperature [째C]')\n",
    "plt.title('TS1 sensor')\n",
    "plt.ylim(30,60)\n",
    "plt.show\n",
    "print(X_1Hz[:,3].shape)\n",
    "\n",
    "# Volume Flow (10 Hz)\n",
    "t = np.linspace(0, 60*5, num=600*5)\n",
    "t_sub = np.linspace(0, 60*5, num=60*5)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t, X_10Hz[:600*5,0])\n",
    "plt.plot(t_sub, X_10Hz_sub[:60*5,0])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Volume flow [l/min]')\n",
    "plt.title('FS1 sensor')\n",
    "# plt.ylim(30,60)\n",
    "plt.show\n",
    "# print(X_10Hz[0:-1:10,0].shape)\n",
    "\n",
    "# Volume Flow (100 Hz)\n",
    "t = np.linspace(0, 60*5, num=6000*5)\n",
    "t_sub = np.linspace(0, 60*5, num=60*5)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t, X_100Hz[:6000*5,1])\n",
    "plt.plot(t_sub, X_100Hz_sub[0:60*5,1])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Pressure [bar]')\n",
    "plt.title('PS1 sensor')\n",
    "# plt.ylim(30,60)\n",
    "plt.show\n",
    "print(X_100Hz[0:-1:100,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a way to increment the number of samples within data\n",
    "# import os\n",
    "# # Data of 1Hz\n",
    "# arr = os.listdir('data/1Hz')\n",
    "\n",
    "# temp = np.loadtxt('data/1Hz/'+arr[0], delimiter='\\t', skiprows=0, dtype=float)\n",
    "# temp = temp.flatten()\n",
    "# temp_ = np.asarray([])\n",
    "# for ii in range(len(temp)):\n",
    "#     for jj in range(100):\n",
    "#         temp_ = np.append(temp_, temp[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score based method: Greedy Equivalent Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate,score = ges.fit_bic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0]\n",
      " [1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0]\n",
      " [1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0]\n",
      " [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      " [1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0]\n",
      " [1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      " [1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
      " [1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0]\n",
      " [1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0]] 296062.73713914165\n",
      "File saved:  adjMat_whole_data_sub\n",
      "File saved:  score_whole_data_sub\n"
     ]
    }
   ],
   "source": [
    "print(estimate,score)\n",
    "save_adjMat_score('whole_data_sub',estimate,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m create_graph_reduced(\u001b[43mestimate\u001b[49m,nodes_full,nodes_full)\n\u001b[0;32m      2\u001b[0m f\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults/Graph_whole_data_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m f\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults/Graph_whole_data_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'estimate' is not defined"
     ]
    }
   ],
   "source": [
    "f = create_graph(estimate, nodes_full, nodes_full)\n",
    "f.render(\"Results/Graph_whole_data_sub\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_whole_data_sub\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severe leakage pump analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1Hz files\n",
      "----------------------------------------\n",
      "['CE.txt', 'CP.txt', 'SE.txt', 'TS1.txt', 'TS2.txt', 'TS3.txt', 'TS4.txt', 'VS1.txt']\n",
      "Data loaded. Matrix shape: (28800, 8)\n",
      "----------------------------------------\n",
      "10Hz files\n",
      "----------------------------------------\n",
      "['FS1.txt', 'FS2.txt']\n",
      "Data loaded. Matrix shape: (288000, 2)\n",
      "Data sub sampled. Matrix shape: (28800, 2)\n",
      "----------------------------------------\n",
      "100Hz files\n",
      "----------------------------------------\n",
      "['EPS1.txt', 'PS1.txt', 'PS2.txt', 'PS3.txt', 'PS4.txt', 'PS5.txt', 'PS6.txt']\n",
      "Data loaded. Matrix shape: (2880000, 7)\n",
      "Data sub sampled. Matrix shape: (28800, 7)\n",
      "----------------------------------------\n",
      "Whole data matrix created!!\n",
      "----------------------------------------\n",
      "(28800, 17)\n"
     ]
    }
   ],
   "source": [
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_MP1_2 = np.where((profile[:,4] == 0) & (profile[:,2] == 2))\n",
    "idx_MP1_2 = np.asarray(idx_MP1_2)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "MP1_2_1Hz = load_data(arr,'data/1Hz/', idx_arr=idx_MP1_2) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', MP1_2_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "MP1_2_10Hz = load_data(arr,'data/10Hz/',idx_arr=idx_MP1_2)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', MP1_2_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "MP1_2_10Hz_sub=MP1_2_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', MP1_2_10Hz_sub.shape)\n",
    "\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "MP1_2_100Hz = load_data(arr,'data/100Hz/', idx_arr=idx_MP1_2)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', MP1_2_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "MP1_2_100Hz_sub=MP1_2_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', MP1_2_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "MP1_2_data = np.concatenate((MP1_2_1Hz, MP1_2_10Hz_sub, MP1_2_100Hz_sub),1)\n",
    "print(MP1_2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP1_2_est, MP1_2_score = ges.fit_bic(MP1_2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0]\n",
      " [1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0]\n",
      " [1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1]\n",
      " [1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      " [1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1]\n",
      " [1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]] 132238.01735495232\n",
      "File saved:  adjMat_MP1_severe_fail\n",
      "File saved:  score_MP1_severe_fail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Results\\\\Graph_MP1_severe_fail.png'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MP1_2_est,MP1_2_score)\n",
    "save_adjMat_score('MP1_severe_fail',MP1_2_est,MP1_2_score)\n",
    "\n",
    "f = create_graph(MP1_2_est,nodes_full,nodes_full)\n",
    "f.render(\"Results/Graph_MP1_severe_fail\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_MP1_severe_fail\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severe leakage pump and V10 100% open analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1Hz files\n",
      "----------------------------------------\n",
      "['CE.txt', 'CP.txt', 'SE.txt', 'TS1.txt', 'TS2.txt', 'TS3.txt', 'TS4.txt', 'VS1.txt']\n",
      "Data loaded. Matrix shape: (7200, 8)\n",
      "----------------------------------------\n",
      "10Hz files\n",
      "----------------------------------------\n",
      "['FS1.txt', 'FS2.txt']\n",
      "Data loaded. Matrix shape: (72000, 2)\n",
      "Data sub sampled. Matrix shape: (7200, 2)\n",
      "----------------------------------------\n",
      "100Hz files\n",
      "----------------------------------------\n",
      "['EPS1.txt', 'PS1.txt', 'PS2.txt', 'PS3.txt', 'PS4.txt', 'PS5.txt', 'PS6.txt']\n",
      "Data loaded. Matrix shape: (720000, 7)\n",
      "Data sub sampled. Matrix shape: (7200, 7)\n",
      "----------------------------------------\n",
      "Whole data matrix created!!\n",
      "----------------------------------------\n",
      "(7200, 17)\n"
     ]
    }
   ],
   "source": [
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_fail2 = np.where((profile[:,2] == 2) & (profile[:,1] == 100)& (profile[:,4] == 0))\n",
    "\n",
    "idx_fail2 = np.asarray(idx_fail2)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "fail2_1Hz = load_data(arr,'data/1Hz/', idx_arr=idx_fail2) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail2_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "fail2_10Hz = load_data(arr,'data/10Hz/', idx_arr=idx_fail2)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail2_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail2_10Hz_sub=fail2_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', fail2_10Hz_sub.shape)\n",
    "\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "fail2_100Hz = load_data(arr,'data/100Hz/', idx_arr=idx_fail2)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail2_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail2_100Hz_sub=fail2_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', fail2_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "fail2_data = np.concatenate((fail2_1Hz, fail2_10Hz_sub, fail2_100Hz_sub),1)\n",
    "print(fail2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail2_est, fail2_score = ges.fit_bic(fail2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fail2_est,fail2_score)\n",
    "save_adjMat_score('fail2',fail2_est,fail2_score)\n",
    "\n",
    "f = create_graph(fail2_est,nodes_full,nodes_full)\n",
    "f.render(\"Results/Graph_fail2\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail2\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V10 100% open analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_fail3 = np.where(profile[:,1] == 100)\n",
    "\n",
    "idx_fail3 = np.asarray(idx_fail3)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "fail3_1Hz = load_data(arr,'data/1Hz/', idx_arr=idx_fail3) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail3_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "fail3_10Hz = load_data(arr,'data/10Hz/', idx_arr=idx_fail3)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail3_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail3_10Hz_sub=fail3_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', fail3_10Hz_sub.shape)\n",
    "\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "fail3_100Hz = load_data(arr,'data/100Hz/', idx_arr=idx_fail3)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail3_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail3_100Hz_sub=fail3_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', fail3_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "fail3_data = np.concatenate((fail3_1Hz, fail3_10Hz_sub, fail3_100Hz_sub),1)\n",
    "print(fail3_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail3_est, fail3_score = ges.fit_bic(fail3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fail3_est,fail3_score)\n",
    "save_adjMat_score('fail3',fail3_est,fail3_score)\n",
    "\n",
    "f = create_graph(fail3_est,nodes_full,nodes_full)\n",
    "f.render(\"Results/Graph_fail3\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail3\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 full efficiency and stability (stable flag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "1Hz files\n",
      "----------------------------------------\n",
      "['TS1.txt', 'TS2.txt', 'VS1.txt', 'CE.txt', 'CP.txt', 'SE.txt']\n",
      "Data loaded. Matrix shape: (600, 6)\n",
      "----------------------------------------\n",
      "10Hz files\n",
      "----------------------------------------\n",
      "['FS1.txt']\n",
      "Data loaded. Matrix shape: (6000, 1)\n",
      "Data sub sampled. Matrix shape: (600, 1)\n",
      "----------------------------------------\n",
      "100Hz files\n",
      "----------------------------------------\n",
      "['PS1.txt', 'PS2.txt', 'PS3.txt', 'EPS1.txt']\n",
      "Data loaded. Matrix shape: (60000, 4)\n",
      "Data sub sampled. Matrix shape: (600, 4)\n",
      "----------------------------------------\n",
      "Whole data matrix created!!\n",
      "----------------------------------------\n",
      "(600, 11)\n"
     ]
    }
   ],
   "source": [
    "sensors = [\"PS1\",\"PS2\",\"PS3\",\"FS1\",\"TS1\",\"TS2\",\"EPS1\",\"VS1\",\"CE\",\"CP\",\"SE\"]\n",
    "\n",
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_fail4 = np.where((profile[:,0] == 100) & (profile[:,1] == 100) & (profile[:,2] == 2) & (profile[:,3] == 130) & (profile[:,4] == 0))\n",
    "idx_fail4 = np.asarray(idx_fail4)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor+'.txt' in arr:\n",
    "        arr1.append(sensor+'.txt')\n",
    "arr = arr1        \n",
    "fail4_1Hz = load_data(arr,'data/1Hz/', idx_arr=idx_fail4) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail4_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor+'.txt' in arr:\n",
    "        arr1.append(sensor+'.txt')\n",
    "arr = arr1   \n",
    "print(arr)\n",
    "fail4_10Hz = load_data(arr,'data/10Hz/', idx_arr=idx_fail4)\n",
    "print('Data loaded. Matrix shape:', fail4_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail4_10Hz_sub=fail4_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', fail4_10Hz_sub.shape)\n",
    "\n",
    "# Loading data sampled at 100Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor+'.txt' in arr:\n",
    "        arr1.append(sensor+'.txt')\n",
    "arr = arr1\n",
    "print(arr)\n",
    "fail4_100Hz = load_data(arr,'data/100Hz/', idx_arr=idx_fail4)\n",
    "print('Data loaded. Matrix shape:', fail4_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail4_100Hz_sub=fail4_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', fail4_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "fail4_data = np.concatenate((fail4_1Hz, fail4_10Hz_sub, fail4_100Hz_sub),1)\n",
    "print(fail4_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail4_est, fail4_score = ges.fit_bic(fail4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fail4_est,fail4_score)\n",
    "save_adjMat_score('fail4',fail4_est,fail4_score)\n",
    "\n",
    "f = create_graph(fail4_est,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail4\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail4\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##con questi dati GNN (600,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 close total failure and stability (stable flag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [\"PS1.txt\",\"PS2.txt\",\"PS3.txt\",\"FS1.txt\",\"TS1.txt\",\"TS2.txt\",\"EPS1.txt\",\"VS1.txt\",\"TS5.txt\",\"CE.txt\",\"CP.txt\",\"SE.txt\"]\n",
    "\n",
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_fail5 = np.where((profile[:,0] == 3) & (profile[:,1] == 100) & (profile[:,2] == 2) & (profile[:,3] == 130) & (profile[:,4] == 0))\n",
    "idx_fail5 = np.asarray(idx_fail5)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1        \n",
    "fail5_1Hz = load_data(arr,'data/1Hz/',failure = True, idx_arr=idx_fail5) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail5_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1        \n",
    "fail5_10Hz = load_data(arr,'data/10Hz/',failure = True, idx_arr=idx_fail5)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail5_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail5_10Hz_sub=fail5_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', fail5_10Hz_sub.shape)\n",
    "\n",
    "# Loading data sampled at 100Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1\n",
    "print(arr)\n",
    "fail5_100Hz = load_data(arr,'data/100Hz/',failure = True, idx_arr=idx_fail5)\n",
    "print('Data loaded. Matrix shape:', fail5_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail5_100Hz_sub=fail5_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', fail5_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "fail5_data = np.concatenate((fail5_1Hz, fail5_10Hz_sub, fail5_100Hz_sub),1)\n",
    "print(fail5_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail5_est, fail5_score = ges.fit_bic(fail5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fail5_est,fail5_score)\n",
    "save_adjMat_score('fail5',fail5_est,fail5_score)\n",
    "\n",
    "f = create_graph_reduced(fail5_est,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail5\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail5\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 reduced efficiency and stability (stable flag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [\"PS1.txt\",\"PS2.txt\",\"PS3.txt\",\"FS1.txt\",\"TS1.txt\",\"TS2.txt\",\"EPS1.txt\",\"VS1.txt\",\"TS5.txt\",\"CE.txt\",\"CP.txt\",\"SE.txt\"]\n",
    "\n",
    "profile = np.loadtxt('data description/profile.txt', delimiter='\\t', skiprows=0, dtype=float)\n",
    "idx_fail6 = np.where((profile[:,0] == 3) & (profile[:,1] == 100) & (profile[:,2] == 2) & (profile[:,3] == 130) & (profile[:,4] == 0))\n",
    "idx_fail6 = np.asarray(idx_fail6)[0]\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('1Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/1Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1        \n",
    "fail6_1Hz = load_data(arr,'data/1Hz/',failure = True, idx_arr=idx_fail6) \n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail6_1Hz.shape)\n",
    "\n",
    "# Loading data sampled at 1Hz\n",
    "print('----------------------------------------')\n",
    "print('10Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/10Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1        \n",
    "fail6_10Hz = load_data(arr,'data/10Hz/',failure = True, idx_arr=idx_fail6)\n",
    "print(arr)\n",
    "print('Data loaded. Matrix shape:', fail6_10Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail6_10Hz_sub=fail6_10Hz[0:-1:10,:]\n",
    "print('Data sub sampled. Matrix shape:', fail6_10Hz_sub.shape)\n",
    "\n",
    "# Loading data sampled at 100Hz\n",
    "print('----------------------------------------')\n",
    "print('100Hz files')\n",
    "print('----------------------------------------')\n",
    "arr = os.listdir('data/100Hz')\n",
    "arr1 = list()\n",
    "for sensor in sensors:\n",
    "    if sensor in arr:\n",
    "        arr1.append(sensor)\n",
    "arr = arr1\n",
    "print(arr)\n",
    "fail6_100Hz = load_data(arr,'data/100Hz/',failure = True, idx_arr=idx_fail6)\n",
    "print('Data loaded. Matrix shape:', fail6_100Hz.shape)\n",
    "# Data Sub sampling \n",
    "fail6_100Hz_sub=fail6_100Hz[0:-1:100,:]\n",
    "print('Data sub sampled. Matrix shape:', fail6_100Hz_sub.shape)\n",
    "\n",
    "# Data matrixes concatenation\n",
    "print('----------------------------------------')\n",
    "print('Whole data matrix created!!')\n",
    "print('----------------------------------------')\n",
    "fail6_data = np.concatenate((fail6_1Hz, fail6_10Hz_sub, fail6_100Hz_sub),1)\n",
    "print(fail6_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail6_est, fail6_score = ges.fit_bic(fail6_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fail6_est,fail6_score)\n",
    "save_adjMat_score('fail6',fail6_est,fail6_score)\n",
    "\n",
    "f = create_graph_reduced(fail6_est,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail6\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail6\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GNN - Gcastle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CASTLE_BACKEND'] = 'pytorch'\n",
    "from castle.common import GraphDAG\n",
    "from castle.algorithms import DAG_GNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# rl learn\n",
    "gnn4 = DAG_GNN(device_type='cpu')\n",
    "gnn4.learn(fail4_data)\n",
    "# plot dag\n",
    "adj4 = gnn4.causal_matrix\n",
    "GraphDAG(adj4)\n",
    "sensors = ['PS1.txt','PS2.txt','PS3.txt','FS1.txt','TS1.txt','TS2.txt','EPS1.txt','VS1.txt','TS5.txt','CE.txt','CP.txt','SE.txt']\n",
    "\n",
    "f = create_graph_reduced(adj4,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail4_GNN\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail4_GNN\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl learn\n",
    "gnn5 = DAG_GNN(device_type='cpu')\n",
    "gnn5.learn(fail5_data)\n",
    "# plot dag\n",
    "adj5 = gnn5.causal_matrix\n",
    "GraphDAG(adj5)\n",
    "sensors = ['PS1.txt','PS2.txt','PS3.txt','FS1.txt','TS1.txt','TS2.txt','EPS1.txt','VS1.txt','TS5.txt','CE.txt','CP.txt','SE.txt']\n",
    "f = create_graph_reduced(adj5,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail5_GNN\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail5_GNN\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rl learn\n",
    "gnn6 = DAG_GNN(device_type='cpu')\n",
    "gnn6.learn(fail6_data)\n",
    "# plot dag\n",
    "adj6 = gnn6.causal_matrix\n",
    "GraphDAG(adj6)\n",
    "sensors = ['PS1.txt','PS2.txt','PS3.txt','FS1.txt','TS1.txt','TS2.txt','EPS1.txt','VS1.txt','TS5.txt','CE.txt','CP.txt','SE.txt']\n",
    "f = create_graph_reduced(adj6,sensors,sensors)\n",
    "f.render(\"Results/Graph_fail6_GNN\", format=\"pdf\")\n",
    "f.render(\"Results/Graph_fail6_GNN\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nszrPfU1bDEh"
   },
   "source": [
    "# **Bibliography:**\n",
    "\n",
    "[1] https://archive-beta.ics.uci.edu/dataset/447/condition+monitoring+of+hydraulic+systems\n",
    "\n",
    "[2] https://ieeexplore.ieee.org/document/7151267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
